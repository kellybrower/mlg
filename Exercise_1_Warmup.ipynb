{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercise 1 - Warmup",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kellybrower/mlg/blob/master/Exercise_1_Warmup.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vi8jPBa-8Nx-",
        "colab_type": "text"
      },
      "source": [
        "![Logo](https://uploads-ssl.webflow.com/5a72b3a09e04c7000168f4de/5ce6005b22f44fde8ced717c_MD%20Horizontal.png)\n",
        "\n",
        "# Octavian.ai machine learning on graphs course\n",
        "\n",
        "Welcome to our summer course on graph ML.\n",
        "\n",
        "This course is primarily exercise based - you'll learn through reading and writing code, and answering the questions throughout these exercises.\n",
        "\n",
        "[Join our Discord](https://discord.gg/a2Z82Te) to chat with fellow enthusiasts about this exercise and give us feedback to direct the next one.\n",
        "\n",
        "## Exercise 1, the warm-up\n",
        "\n",
        "This is the first installment of our course! Thanks for joining us. \n",
        "\n",
        "In this exercise, I'll introduce you to:\n",
        "\n",
        "- [Tensorflow 2.0](https://www.tensorflow.org/alpha)\n",
        "- Python 3\n",
        "- Working with simple graph data\n",
        "- Classifying nodes in a graph\n",
        "\n",
        "There will be questions, areas to write code and also some discussion of choices made in crafting this.\n",
        "\n",
        "\n",
        "### The problem we'll work with\n",
        "\n",
        "In this exercise we will predict the political orientation (left learning vs right leaning) of a blog based on which other blogs it has links to/from.\n",
        "\n",
        "Our graph nodes will be blogs (e.g. a single domain with many pages) and the edges will be the links that blog has to other blogs (from any of its pages).\n",
        "\n",
        "This is a pretty neat dataset, from the paper [The Political Blogosphere and the 2004 U.S. Election: Divided They Blog](http://www.ramb.ethz.ch/CDstore/www2005-ws/workshop/wf10/AdamicGlanceBlogWWW.pdf). \n",
        "\n",
        "You can [download graph data here](http://konect.uni-koblenz.de/networks/moreno_blogs), however the solution template below will do that for you automatically.\n",
        "\n",
        "\n",
        "\n",
        "### Solution approach\n",
        "\n",
        "This is a fascinating problem as you can take many different approaches to it, from hand-crafted heuristics to complex machine learning.\n",
        "\n",
        "For the purposes of this warm-up, we’ll take a simple approach. It won’t be as capable as other approaches (e.g. its test accuracy will be sub-optimal).\n",
        "\n",
        "We’ll learn a function that determines a node’s political orientation L given its set of neighbours (represented as an unordered list of their orientations).\n",
        "\n",
        "The function will be a simple machine learning function. You'll write a simple dense layer for the first version, and then are encouraged to try other functions to see if they perform better.\n",
        "\n",
        "---\n",
        "\n",
        "## Get the data\n",
        "\n",
        "The first step in most machine learning experiments is to get hold of the required data.\n",
        "\n",
        "Universität Koblenz-Landau kindly have hosted this data. First let's download it and unarchive it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBPgpvjkENXF",
        "colab_type": "code",
        "outputId": "cbc689aa-2721-446b-f285-2f7c61ef8a49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        }
      },
      "source": [
        "# Get data\n",
        "\n",
        "!wget http://konect.uni-koblenz.de/downloads/tsv/moreno_blogs.tar.bz2\n",
        "!tar xfvj moreno_blogs.tar.bz2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-06-11 04:28:04--  http://konect.uni-koblenz.de/downloads/tsv/moreno_blogs.tar.bz2\n",
            "Resolving konect.uni-koblenz.de (konect.uni-koblenz.de)... 141.26.208.254\n",
            "Connecting to konect.uni-koblenz.de (konect.uni-koblenz.de)|141.26.208.254|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 49912 (49K) [application/octet-stream]\n",
            "Saving to: ‘moreno_blogs.tar.bz2.4’\n",
            "\n",
            "moreno_blogs.tar.bz 100%[===================>]  48.74K   225KB/s    in 0.2s    \n",
            "\n",
            "2019-06-11 04:28:05 (225 KB/s) - ‘moreno_blogs.tar.bz2.4’ saved [49912/49912]\n",
            "\n",
            "moreno_blogs.tar.bz2\tmoreno_blogs.tar.bz2.2\tmoreno_blogs.tar.bz2.4\n",
            "moreno_blogs.tar.bz2.1\tmoreno_blogs.tar.bz2.3\tsample_data\n",
            "moreno_blogs/\n",
            "moreno_blogs/out.moreno_blogs_blogs\n",
            "moreno_blogs/meta.moreno_blogs_blogs\n",
            "moreno_blogs/README.moreno_blogs\n",
            "moreno_blogs/ent.moreno_blogs_blogs.blog.orientation\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HArvXyS3fDuv",
        "colab_type": "text"
      },
      "source": [
        "Next, let's get the python libraries we'll need for the code:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KVsQeWUStwf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set up Python environment\n",
        "!pip install -q tensorflow==2.0.0-alpha0\n",
        "\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Poaqqi6fJ3H",
        "colab_type": "text"
      },
      "source": [
        "Let's also define a couple of constants for later on:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwOACp-LyaMT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define constants\n",
        "\n",
        "# How many neighhbors to consider when predicting a node's label\n",
        "# The fact that we fix this is quite interesting, more discussion\n",
        "# of this later.\n",
        "FIXED_NEIGHBOR_SIZE = 10\n",
        "\n",
        "# The batch size we'll bucket our data into before running the machine\n",
        "# learning functions\n",
        "BATCH_SIZE = 32"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCrP-GR4fdOI",
        "colab_type": "text"
      },
      "source": [
        "And now for processing the data.\n",
        "\n",
        "There are two files we'll process from the download:\n",
        "\n",
        "\n",
        "*   `out.moreno_blogs_blogs` Graph edges, expressed as pairs of node indices, where the first index is 1\n",
        "*  `ent.moreno_blogs_blogs.blog.orientation` The label (left-leaning or right-leaning) of each blog, expressed as one label per line, with the first line being the label for blog index 1\n",
        "\n",
        "\n",
        "To get the data ready for machine learning we need to represent it as training examples for the network. Our example format will be:\n",
        "* Input data: A list of neighbor labels, each represented as one-hot vectors left-leaning=[1,0] or right-learning[0,1]. \n",
        "* Expected output: A label, represented as an integer left-leaning=0 or right-leaning=1\n",
        "\n",
        "The machine learning function will try to learn a mapping between the input data and expected output.\n",
        "\n",
        "Once we've created the list of examples, we split them into training data (90% of the total) and test data (10% of the total)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGq9QH35q8Hg",
        "colab_type": "code",
        "outputId": "15ab1559-74ab-40e9-bff3-449d00897d3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "# Load the data\n",
        "\n",
        "import random\n",
        "import csv\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter\n",
        "import itertools\n",
        "\n",
        "\n",
        "def label_to_int(label):\n",
        "  '''\n",
        "    An incredibly simple token embedding. Translates binary tokens into int\n",
        "  '''\n",
        "  if label == 'left-leaning':\n",
        "    return 0\n",
        "  else:\n",
        "    return 1\n",
        "\n",
        "def label_to_vec(label):\n",
        "  '''\n",
        "    An incredibly simple token embedding. Translates binary tokens into one-hot vector\n",
        "  '''\n",
        "  if label == 'left-leaning':\n",
        "    return [1,0]\n",
        "  else:\n",
        "    return [0,1]\n",
        "\n",
        "def load_data():\n",
        "  '''\n",
        "    Transform data into the format needed for our training\n",
        "  '''\n",
        "  \n",
        "  edges = []\n",
        "  \n",
        "  with open('/content/moreno_blogs/out.moreno_blogs_blogs') as f:\n",
        "    reader = csv.reader(f, delimiter=' ')\n",
        "    for i in reader:\n",
        "      if i[0] != \"%\":\n",
        "        edges.append( (int(i[0])-1, int(i[1])-1) )\n",
        "      \n",
        "  labels = []\n",
        "  \n",
        "  with open('/content/moreno_blogs/ent.moreno_blogs_blogs.blog.orientation') as f:\n",
        "    reader = csv.reader(f, delimiter=' ')\n",
        "    for i in reader:\n",
        "      labels.append(i[0])\n",
        "      \n",
        "      \n",
        "  # Dataset for test and training\n",
        "  # (where L is a left/right label)\n",
        "  \n",
        "  # X are inputs: [L, L, L, L] list of neighbor labels\n",
        "  X = []\n",
        "  \n",
        "  # y are labels\n",
        "  y = []\n",
        "  \n",
        "  for (node_id, label) in enumerate(labels):\n",
        "    neighbors = set()\n",
        "    for (v1, v2) in edges:\n",
        "      if v1 == node_id:\n",
        "        neighbors.add(v2)\n",
        "      if v2 == node_id:\n",
        "        neighbors.add(v1)\n",
        "        \n",
        "    try:\n",
        "      neighbors.remove(node_id)\n",
        "    except:\n",
        "      # It's fine, we're just guarding against self-reference that would make this\n",
        "      # exercise a bit easier\n",
        "      pass\n",
        "        \n",
        "    neighbor_labels = [label_to_vec(labels[i]) for i in neighbors]\n",
        "    random.shuffle(neighbor_labels)\n",
        "    \n",
        "    X.append(neighbor_labels)\n",
        "    y.append(label_to_int(label))\n",
        "    \n",
        "  return X, y\n",
        "    \n",
        "\n",
        "X, y = load_data()\n",
        "\n",
        "print(\"Data statistics\")\n",
        "print(\"Number of data-points\", len(X))\n",
        "print(\"Average number of neighbors\", np.average([len(i) for i in X]))\n",
        "print(\"Max number of neighbors\", np.max([len(i) for i in X]))\n",
        "print(\"Min number of neighbors\", np.min([len(i) for i in X]))\n",
        "print(\"Distribution of labels\", Counter(y))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
        "\n",
        "print()\n",
        "print(\"Number of training examples\", len(X_train))\n",
        "print(\"Distribution of labels\", Counter(y_train))\n",
        "print(\"Example: \", X_train[90], \" has label \", y_train[90])\n",
        "\n",
        "print()\n",
        "print(\"Number of test examples\", len(X_test))\n",
        "print(\"Distribution of labels\", Counter(y_test))\n",
        "print(\"Example: \", X_test[0], \" has label \", y_test[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data statistics\n",
            "Number of data-points 1224\n",
            "Average number of neighbors 27.312091503267975\n",
            "Max number of neighbors 351\n",
            "Min number of neighbors 1\n",
            "Distribution of labels Counter({1: 636, 0: 588})\n",
            "\n",
            "Number of training examples 1040\n",
            "Distribution of labels Counter({1: 542, 0: 498})\n",
            "Example:  [[0, 1], [0, 1], [0, 1], [0, 1], [1, 0], [1, 0], [1, 0], [1, 0], [0, 1], [1, 0], [1, 0]]  has label  1\n",
            "\n",
            "Number of test examples 184\n",
            "Distribution of labels Counter({1: 94, 0: 90})\n",
            "Example:  [[1, 0], [1, 0]]  has label  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IA7GVElwiIWu",
        "colab_type": "text"
      },
      "source": [
        "Now that we have our data represented as python lists, we will package it up for TensorFlow into [Dataset](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/data/Dataset) instances.\n",
        "\n",
        "### Fixed sized data\n",
        "\n",
        "As alluded to earlier, TensorFlow strongly prefers our data to be of fixed size. In our input data we include a list of each nodes' neighbors. A node can have any number of neighbors, from zero to every other node in the graph. This is certainly not a fixed sized list!\n",
        "\n",
        "To solve this, here I define a function to force the lists to be an exact size - either by padding them or cropping them. This is bad for a few reasons:\n",
        "* It throws away useful information if there are too many edges\n",
        "* It creates extra arithmetic work for the machine learning to do when there are too few edges\n",
        "\n",
        "**QUESTIONS FOR KEEN STUDENTS:** \n",
        "* Why does TensorFlow prefer fixed sized data? \n",
        "* How can we feed variable length data into TensorFlow and what are the downsides? \n",
        "* How much of a problem is it if we discard some edges?\n",
        "* How much of a problem is it if we use a really `high target_len`?\n",
        "* What other approaches could we take to solving this problem? \n",
        "\n",
        "Note that this is a somewhat unsolved problem in Graph Machine Learning, you won't find a simple answer. In considering the trade-offs and roots of this problem, you'll be better equiped to develop successful systems.\n",
        "\n",
        "### Datasets\n",
        "\n",
        "We use the TensorFlow Dataset object for easy data manipulation. This also lets us:\n",
        "* Split the data into [mini-batches](https://machinelearningmastery.com/gentle-introduction-mini-batch-gradient-descent-configure-batch-size/)\n",
        "* Shuffle the data (the default is that it'll be reshuffled each epoch)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-7_i738h6aE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def fix_size_of_list(data, target_len=FIXED_NEIGHBOR_SIZE):\n",
        "  '''\n",
        "  This function highlights one of the central challenges of graph data:\n",
        "  it is naturally variable sized and frameworks like TensorFlow want\n",
        "  fixed sized tensor data.\n",
        "  \n",
        "  Our simplistic solution is to fix the size - we chop it down if too large, or\n",
        "  zero pad it if too small.\n",
        "  '''\n",
        "  \n",
        "  delta = len(data) - target_len\n",
        "  \n",
        "  if delta >= 0:\n",
        "    return data[0:target_len]\n",
        "  else:\n",
        "    return np.pad(data, [(0, -delta), (0,0)], mode='constant', constant_values=0)\n",
        "\n",
        "\n",
        "# Create TensorFlow dataset objects ready for training and evaluation\n",
        "\n",
        "## Training data\n",
        "\n",
        "X_train_fixed = [fix_size_of_list(i) for i in X_train]\n",
        "\n",
        "dataset_train = tf.data.Dataset.from_tensor_slices(( X_train_fixed , y_train))\n",
        "dataset_train = dataset_train.batch(BATCH_SIZE)\n",
        "dataset_train = dataset_train.shuffle(BATCH_SIZE * 10)\n",
        "\n",
        "## Test data\n",
        "\n",
        "X_test_fixed = [fix_size_of_list(i) for i in X_test]\n",
        "\n",
        "dataset_test = tf.data.Dataset.from_tensor_slices(( X_test_fixed , y_test))\n",
        "dataset_test = dataset_test.batch(BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAaFh-et5v8U",
        "colab_type": "text"
      },
      "source": [
        "# The machine learning model\n",
        "\n",
        "Welcome to the exciting part - we've got our data in order and now we get to engineer a model to solve it.\n",
        "\n",
        "We'll use the [Keras API](https://keras.io) here as it's simple and quick to get running. \n",
        "\n",
        "There are a couple of steps to our model:\n",
        "\n",
        "1. Define a sequence of layers\n",
        "2. Compile the model to use our desired loss function, optimizer and metrics\n",
        "3. Train the model to fit our training data\n",
        "4. Evaluate the model on our test data\n",
        "\n",
        "The goal is to get as high a test accuracy as possible (e.g. how well the model predicts labels on the test data after training on the training data).\n",
        "\n",
        "Our model takes a list of neighbor labels, and outputs the probablilty of each possible label (`left-leaning` or `right-leaning`) as a vector of width two (since it represents a [one-hot-vector](https://hackernoon.com/what-is-one-hot-encoding-why-and-when-do-you-have-to-use-it-e3c6186d008f)). We use a [softmax](http://cs231n.github.io/linear-classify/#softmax) activation to push the vector into looking like a probability distribution (e.g. it sums to 1.0)\n",
        "\n",
        "**EXERCISE**: Add a [dense layer](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0TmIQSpErmY",
        "colab_type": "code",
        "outputId": "8491142e-d6aa-4796-d30b-0be1099613b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "model = keras.Sequential([\n",
        "  layers.Input(shape=[FIXED_NEIGHBOR_SIZE, 2]),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(2),\n",
        "  layers.Softmax()\n",
        "])\n",
        "\n",
        "model.summary()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_1 (Flatten)          (None, 20)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 42        \n",
            "_________________________________________________________________\n",
            "softmax_1 (Softmax)          (None, 2)                 0         \n",
            "=================================================================\n",
            "Total params: 42\n",
            "Trainable params: 42\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OuLOm3Dvoa9-",
        "colab_type": "text"
      },
      "source": [
        "Now the model's written, we can train and test it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziEh3RzkoY7P",
        "colab_type": "code",
        "outputId": "318662b7-cf15-441f-a921-675a09cf9f5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        }
      },
      "source": [
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "print(\"Training:\")\n",
        "history = model.fit(dataset_train, epochs=13, verbose=1)\n",
        "\n",
        "print(\"\\n\\nFinal test accuracy:\")\n",
        "\n",
        "results = model.evaluate(dataset_test)\n",
        "\n",
        "for l, v in zip(model.metrics_names, results):\n",
        "  print(l, v)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training:\n",
            "Epoch 1/13\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.9694 - accuracy: 0.2654\n",
            "Epoch 2/13\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7800 - accuracy: 0.5356\n",
            "Epoch 3/13\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.6432 - accuracy: 0.6462\n",
            "Epoch 4/13\n",
            "33/33 [==============================] - 0s 1ms/step - loss: 0.5468 - accuracy: 0.6933\n",
            "Epoch 5/13\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.4781 - accuracy: 0.7481\n",
            "Epoch 6/13\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.7837\n",
            "Epoch 7/13\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.3895 - accuracy: 0.7856\n",
            "Epoch 8/13\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.3598 - accuracy: 0.8115\n",
            "Epoch 9/13\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.3361 - accuracy: 0.8519\n",
            "Epoch 10/13\n",
            "33/33 [==============================] - 0s 1ms/step - loss: 0.3167 - accuracy: 0.8663\n",
            "Epoch 11/13\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.3007 - accuracy: 0.9221\n",
            "Epoch 12/13\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.2872 - accuracy: 0.9346\n",
            "Epoch 13/13\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.2757 - accuracy: 0.9365\n",
            "\n",
            "\n",
            "Final test accuracy:\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.2218 - accuracy: 0.9348\n",
            "loss 0.22181462744871774\n",
            "accuracy 0.9347826\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sll-5EZ3XPCj",
        "colab_type": "code",
        "outputId": "3775a300-5aeb-420e-c8f5-ae8f6ca41e37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        }
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "\n",
        "training_loss = history.history['loss']\n",
        "training_acc = history.history['accuracy']\n",
        "#test_loss = history.history['val_loss']\n",
        "\n",
        "epoch_count = range(1, len(training_loss)+1)\n",
        "\n",
        "#plt.figure(figsize=[8,6])\n",
        "line1 = plt.plot(epoch_count, training_loss, 'r--', linewidth=2.0)\n",
        "line2 = plt.plot(epoch_count, training_acc, 'b-', linewidth=1.0)\n",
        "plt.xlabel('Epochs ', fontsize=16)\n",
        "plt.legend(['Loss', 'Accuracy'])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEPCAYAAAC5sYRSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/w/LPCIvF0OfFgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKY3MNq6l6hx",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "## Exercise\n",
        "\n",
        "The first half of the exercise is simply to understand and think about the code shared above. If this is as far as you get, that’s ok - there will be more exercises later and more “fill in the code blanks”.\n",
        "\n",
        "The second half is to try altering the code and see how your changes perform. The important thing is trying out things and thinking about how they perform, this is the core skill of research.\n",
        "\n",
        "### Things to try\n",
        "\n",
        "- Complete the code above, run the notebook and see it work!\n",
        "- What happens if you increase the number of training epochs? Decrease them? ([hint](https://hackernoon.com/what-is-one-hot-encoding-why-and-when-do-you-have-to-use-it-e3c6186d008f))\n",
        "- What is the worst test accuracy this model could achieve?\n",
        "- See what test accuracy the code achieves - does it seem good or bad?\n",
        "- Come up with an explanation of why it achieves this test accuracy\n",
        "- Try to improve the test accuracy. These may or may not work, record in the experiment log below your findings.\n",
        "  - Try editing the fixed size of the neighbor list\n",
        "  - Try more dense layers\n",
        "  - Try a 1d convolution across the neighbors’ labels, then sum that\n",
        "  - Try including the neighbors’ neighbors in the dataset and see if that helps\n",
        "  - Try including the adjacency matrix and performing multiple iterations of graph-convolution\n",
        "  - Try a harder variation of this problem: Remove x% of the neighbor labels and see how well your solution categorizes the nodes.\n",
        "  \n",
        "  \n",
        "  ### Experiment log\n",
        "  \n",
        "  * Experiment tried e.g. I added a second dense layer\n",
        "    * Result e.g. Test accuracy was XX%\n",
        "    * Observations e.g. I saw the loss plateux in epoch X\n",
        "\n",
        "\n"
      ]
    }
  ]
}