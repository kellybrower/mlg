{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercise 3 - Link_Prediction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kellybrower/mlg/blob/master/Exercise_3_Link_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JS3SBY4fOadG",
        "colab_type": "text"
      },
      "source": [
        "![Logo](https://uploads-ssl.webflow.com/5a72b3a09e04c7000168f4de/5ce6005b22f44fde8ced717c_MD%20Horizontal.png)\n",
        "\n",
        "# Octavian.ai machine learning on graphs course\n",
        "\n",
        "Welcome to our course on graph ML.\n",
        "\n",
        "This course is primarily exercise based - you'll learn through reading and writing code, and answering the questions throughout these exercises.\n",
        "\n",
        "[Join our Discord](https://discord.gg/a2Z82Te) to chat with fellow enthusiasts about this exercise and give us feedback to direct the next one.\n",
        "\n",
        "## Exercise 3, graph convolutional networks - link prediction\n",
        "In this exercise, you will learn how to predict edges in a graph. We'll do this by creating a graph network that passes messages along the edges of the graph. This technique is very versatile and with creativity can be applied to a wide range of graph problems.\n",
        "\n",
        "Also, this course will emphasize the following new content:\n",
        "\n",
        "* What is link prediction?\n",
        "\n",
        "* What is negative sampling and how is it relevant to link prediction?\n",
        "\n",
        "* What is an encoder/decoder and how does it relate to node embeddings?\n",
        "\n",
        "* How do we leverage the model's embeddings to do link predictions?\n",
        "\n",
        "\n",
        "## Introduction to Link Prediction in Graphs\n",
        "\n",
        "### Problem Statement\n",
        "\n",
        "Given the current state of graph, the goal is to predict the likelihood of a future association (link or edge) between two nodes, knowing that there is no association between the nodes in the current state of the graph. \n",
        "\n",
        "<img src=\"https://media.springernature.com/original/springer-static/image/art%3A10.1007%2Fs10462-017-9590-2/MediaObjects/10462_2017_9590_Fig2_HTML.gif\" width=\"70%\"/>\n",
        "\n",
        "Figure 1\n",
        "\n",
        "The image on the left above uses dashed lines to represent links that are missing from the graph. The image on the right uses yellow lines to indicate links that have been predicted to occur in the future. Moreoever:\n",
        "\n",
        ">In effect, the link prediction problem asks: to what extent can the evolution of a social network be modeled using features intrinsic to the network topology itself? Can the current state of the network be used to predict future links? The link prediction problem is also related to the problem of inferring missing links from an observed network: in a number of domains, one constructs a network of interactions based on observable data and then tries to infer additional links that, while not directly visible, are likely to exist. [Link Prediction Algorithms](http://be.amazd.com/link-prediction/)\n",
        "\n",
        "### Applications\n",
        "Beyond social networks, link prediction has many other applications:\n",
        "* In bioinformatics, link prediction can be used to find interactions between proteins [Airoldi et al. 2006](http://jmlr.csail.mit.edu/papers/volume9/airoldi08a/airoldi08a.pdf)\n",
        "* In e-commerce, it can help build recommendation systems [Huang et al. 2005](https://www.researchgate.net/publication/263652875_A_graph_model_for_e-commerce_recommender_systems) such as the \"people who bought this also bought\" feature on Amazon\n",
        "* In the security domain, link prediction can assist in identifying hidden groups of terrorists or criminals [Hasan et al. 2006](http://www.cs.rpi.edu/~zaki/PaperDir/LINK06.pdf).\n",
        "* In co-authorship networks, many studies have been carried out (for example in scientific journals, with edges joining pairs who have co-authored papers). \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OE7MX87z_umg",
        "colab_type": "text"
      },
      "source": [
        "## Background on Link Prediction\n",
        "\n",
        "How can you split a graph to achieve a learning task? First of all it is important to remember precisely our purpose : **we want to predict links (edges) between nodes**. \n",
        "\n",
        "The first capital information is the following one : the predictive algorithm will take as input node pairs and evaluate whether the nodes present the properties to be linked in the future. What remains to be clarified now is the output : how can we create ground-truth labels from the graph? The idea is to take a graph, hide some of its edges and monitor the results produced by the algorithm. For hidden links the label is 1, for non-existent links it is 0. No problem, let’s illustrate the concept with a minimal example:\n",
        "\n",
        "<img src=\"https://i.ibb.co/DgC8jcB/full-test-training-graph.png\" width=\"60%\"/>\n",
        "\n",
        "Figure 2\n",
        "\n",
        "From the left to the right we have :\n",
        "\n",
        "* The \"full graph” which denotes as G_valid = (V, E_valid) with : V = {A, B, C, D, E, F, G, H, I, J} and E_valid = {(A,B); (A, D); (B, C); (B, D); (B, E); (C, D); (D, E); (D, F); (D, H); (D, G); (E, F); (E, I); (F, H); (F, I); (F, J); (I, J)}.\n",
        "* The “test graph” where we have hidden two edges : G_test = (V, E_test) with E_test = E_valid \\ {(D, E); (D, H)} thus E_test ⊂ E_valid.\n",
        "* The “training graph” where we have hidden four more edges : G_train = (V, E_train) with E_train = E_test \\ {(A, D); (C, D); (E, I); (F, J)} thus E_train ⊂ E_test.\n",
        "\n",
        "The training set (with the corresponding labels) looks like the table below.\n",
        "\n",
        "<img src=\"https://hackernoon.com/hn-images/1*230lw-B4t405x6rFJk2FvQ.png\" width=\"15%\"/>\n",
        "\n",
        "The edge (D, H) for example has the label 0 here because it doesn’t exist in the Test Graph, even though it was originally present in the Validation Graph.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pdgil7_1e8Kf",
        "colab_type": "text"
      },
      "source": [
        "### Negative Sampling\n",
        "\n",
        "First, some definitions:\n",
        "* If the link exists in the graph, it is a *positive* sample. \n",
        "* If the link does not exist in the graph, it is a *negative* sample. \n",
        "\n",
        "The need of negative sampling comes from the fact that there are only positive examples in the dataset. To avoid trivial solutions of the embedding, for each positive sample in the dataset a set that contains its all possible negative samples needs to be hand-made.\n",
        "\n",
        "In this demo, negative samples are generated by iterating through all the i-j node pairs (links) in the adjacency matrix, and checking if the link exists (meaning it is a positive example). If it does not exist, it is placed in a negative sample dataset.  See the code block below for details on how negative training samples are generated from the well-known Karate Club graph:\n",
        "\n",
        "![Karate Club Graph](https://tkipf.github.io/graph-convolutional-networks/images/karate.png)\n",
        "\n",
        "Figure 3\n",
        "\n",
        "Karate club graph, colors denote communities obtained via modularity-based clustering ([Brandes et al., 2008](http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.68.6623).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwWkFBhn49u_",
        "colab_type": "code",
        "outputId": "3ff286f5-5fd6-451f-a7bb-3b9b0a84f52e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "import networkx as nx\n",
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "\n",
        "# Utility method for converting a coordinate matrix to tuple form for easier inspection of the edge coordinates and number of edges\n",
        "def sparse_to_tuple(sparse_mx):\n",
        "    if not sp.isspmatrix_coo(sparse_mx):\n",
        "        sparse_mx = sparse_mx.tocoo()\n",
        "    coords = np.vstack((sparse_mx.row, sparse_mx.col)).transpose()\n",
        "    values = sparse_mx.data\n",
        "    shape = sparse_mx.shape\n",
        "    return coords, values, shape\n",
        "\n",
        "  # This function creates test edges for graphs with non-directed edges\n",
        "def create_test_edges(g, percent_test_edges=10):\n",
        "    # Create adjacency matrix from which we can derive the existing (positive) edges.\n",
        "    adj = nx.adjacency_matrix(g)\n",
        "\n",
        "    # To simplify this algorithm, we will ignore self-edges: remove diagonal elements from the adj matrix\n",
        "    adj = adj - sp.dia_matrix((adj.diagonal()[np.newaxis, :], [0]), shape=adj.shape)\n",
        "\n",
        "    # Check that diagonal is zero:\n",
        "    assert np.diag(adj.todense()).sum() == 0\n",
        "\n",
        "    # In a non-directed graph, the entries in the adj matrix in the upper triangle of the adj matrix refer to the same\n",
        "    # edges in the lower triangle. To avoid these duplicate edges, just use the upper triangle.\n",
        "    # Example: [1, 3] in the upper triangle refers to the same [3, 1] edge in the lower.\n",
        "    adj_triu = sp.triu(adj)\n",
        "\n",
        "    # Convert to tuple form for easier handling\n",
        "    adj_tuple = sparse_to_tuple(adj_triu)\n",
        "\n",
        "    # In tuple form, adj_tuple[0] references the numpy N-dimensional array of edges (e.g., [0 1] [0 2] [0 3] ...)\n",
        "    edges = adj_tuple[0]\n",
        "\n",
        "    # N-dimensional array edges.shape[0] dereferences the number of rows (edges) in the array.\n",
        "    all_edge_idx = list(range(edges.shape[0]))\n",
        "    np.random.shuffle(all_edge_idx)\n",
        "\n",
        "    # Get number of test edges from the 'percent_test_edges' parameter\n",
        "    # Example1: if we want 5% of all edges to be test ones, divide (100 / 5) = 20\n",
        "    # Example2: if we want 10% of all edges to be test ones, divide (100 / 10) = 10\n",
        "    num_test = int(np.floor(edges.shape[0] / (100. / percent_test_edges)))\n",
        "\n",
        "    # Get 'num_test' number of test id indices.\n",
        "    test_edge_idx = all_edge_idx[:num_test]\n",
        "\n",
        "    # Get the test_edges using the test_edge_idx indices\n",
        "    test_edges = edges[test_edge_idx]\n",
        "\n",
        "    def ismember(a, b, tol=5):\n",
        "        # calculate the difference between edges (i-j pairs) in arrays 'a' and 'b'.\n",
        "        diff = a - b\n",
        "        # If two edges in a and b have the same i-j values (e.g., a = [1, 2] b =[1, 2]), their difference is [0 0]\n",
        "        # Check if both values in each member of the diff array are 0.  If they are, return True. Else, False.\n",
        "        # Apply np.all to y-axis of the diff array (axis=1)\n",
        "        rows_close = np.all((diff) == 0, axis=1)\n",
        "        # If any of the diff pairs has a value of True (means 'a' was found in 'b'), return True, Otherwise, False.\n",
        "        return np.any(rows_close)\n",
        "\n",
        "    # Get all edges from the original adj matrix. We will need to check j-i entries as duplicates below\n",
        "    edges_all = sparse_to_tuple(adj)[0]\n",
        "\n",
        "    test_edges_false = []\n",
        "    while len(test_edges_false) < len(test_edges):\n",
        "        idx_i = np.random.randint(0, adj.shape[0])\n",
        "        idx_j = np.random.randint(0, adj.shape[0])\n",
        "        # Since we have randomized the idx_i and idx_j values, we need to check for self-edges (e.g., [1, 1], [2, 2])\n",
        "        # If we have a self-edge, ignore as we not are not modeling these kinds of edges.\n",
        "        if idx_i == idx_j:\n",
        "            continue\n",
        "        # Since we have randomized the idx_i and idx_j values, we need to check all the edges to see if this edge\n",
        "        # already exists. If it does, it is a positive edge, and thus not a candidate for the test_edges_false dataset.\n",
        "        if ismember([idx_i, idx_j], edges_all):\n",
        "            continue\n",
        "        # Since we have randomized the idx_i and idx_j values, we need to check if idx_i and idx_j already exist in\n",
        "        # the test_edges_false dataset. If they already exist, continue.\n",
        "        if test_edges_false:\n",
        "            if ismember([idx_j, idx_i], np.array(test_edges_false)):\n",
        "                continue\n",
        "            if ismember([idx_i, idx_j], np.array(test_edges_false)):\n",
        "                continue\n",
        "        # Since all checks for invalid test edges have passed, add [idx_i, idx_j] to  test_edges_false\n",
        "        test_edges_false.append([idx_i, idx_j])\n",
        "\n",
        "    return test_edges, test_edges_false\n",
        "\n",
        "# Get the popular karate club graph\n",
        "g = nx.karate_club_graph()\n",
        "\n",
        "# Generate positve and negative (false) edge datasets. Reminder: negative (false) edges do not exist in the karate club graph.\n",
        "test_edges, test_edges_false = create_test_edges(g)\n",
        "print(\"test_edges: \", test_edges)\n",
        "print(\"test_edges_false:\", test_edges_false)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_edges:  [[ 1 21]\n",
            " [ 2  7]\n",
            " [ 2 28]\n",
            " [29 32]\n",
            " [ 0 10]\n",
            " [ 2  3]\n",
            " [13 33]]\n",
            "test_edges_false: [[7, 11], [25, 10], [18, 21], [29, 7], [30, 24], [14, 28], [23, 3]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FCTo2PN_930",
        "colab_type": "text"
      },
      "source": [
        "## Theoretical background\n",
        "\n",
        "The central problem in machine learning on graphs is finding a way to incorporate information about graph structure into a machine learning model. For example, in the case of link prediction in a social network, one\n",
        "might want to encode pairwise properties between nodes, such as relationship strength or the number of common friends. \n",
        "\n",
        "To extract structural information from graphs, traditional machine approaches often rely on summary graph statistics (e.g., degrees or clustering coefficients), kernel functions, or carefully engineered features to measure local neighborhood structures. However, these approaches are limited because these handengineered features are inflexible—i.e., they cannot adapt during the learning process—and designing these features can be a time-consuming and expensive process.\n",
        "\n",
        "### Encoding Structural Information from the Graph: Embeddings\n",
        "\n",
        "More recently, there has been a surge of approaches that seek to ***learn representations*** that ***encode*** structural information about the graph. The idea behind these representation learning approaches is to learn a mapping that *embeds* nodes, or entire (sub)graphs, as points in a low-dimensional vector space *&#8477;<sup>d</sup>*. \n",
        "\n",
        "The goal is to optimize this mapping so that geometric relationships in the embedding space reflect the structure of the original graph. Below is an example of the Karate Club node classifications using 2-dimensional latent space which we can immediately visualize. \n",
        "\n",
        "![](https://tkipf.github.io/graph-convolutional-networks/images/karate_emb.png)\n",
        "\n",
        "Figure 4\n",
        "\n",
        "GCN embedding (with random weights) for nodes in the karate club network.\n",
        "\n",
        "After optimizing the embedding space, the learned embeddings can be used as feature inputs for downstream machine learning tasks. The key distinction between representation learning approaches and previous work is how they treat the problem of representing graph structure. Representation learning approaches treat this problem as machine learning task itself, using a data-driven approach to learn ***embeddings*** that encode graph structure. [Hamilton, Yang, Jeskovich, 2017](https://arxiv.org/pdf/1709.05584.pdf). \n",
        "\n",
        "### Notation and Essential Assumptions\n",
        "\n",
        "We will assume that the primary input to our representation learning algorithm is an undirected graph *G = (V, E)* with associated binary adjacency matrix A.  We also assume that the methods can make use of a real-valued matrix of node attributes *X ∈ &#8477;<sup>m×|V|</sup>*, m: number of samples (e.g., representing text or metadata associated with nodes). The goal is to use the information contained in A and X to map each node, or a subgraph, to a vector *z ∈ &#8477;<sup>d</sup>*, where *d << |V|*.  We will optimize this mapping in an unsupervised manner, making use of only information in A and X, without knowledge of a particular downstream machine learning task. \n",
        "\n",
        "## Encoder-Decoder Overview\n",
        "\n",
        "Recent years have seen a surge of research on node embeddings. The goal is to train our embedding to represent liklihood of edges between nodes. Below is a diagram that illustrates the encoder-decoder approach. \n",
        "\n",
        "<img src=\"https://i.ibb.co/vCn22wj/encoder-decoder.png\" width=\"60%\"/>\n",
        "\n",
        "Figure 5\n",
        "\n",
        "First the encoder maps the node, v<sub>i</sub>, to a low-dimensional vector embedding, ***z<sub>i</sub>***, based on the node’s position in the graph, its local neighborhood structure, and/or its attributes. Next, the decoder extracts user-specified information from the low-dimensional embedding. This might be information about v<sub>i</sub>’s local graph neighborhood (e.g., the identity of its neighbors) or a classification label associated with v<sub>i</sub> (e.g., a community label). By jointly optimizing the encoder and decoder, the system learns to compress information about graph structure into the low-dimensional embedding space. \n",
        "\n",
        "The intuition behind the encoder-decoder idea is the following: \n",
        "\n",
        "> if we can learn to decode high-dimensional graph information—such as the global positions of nodes in the graph or the structure of local graph neighborhoods—from encoded low-dimensional embeddings, then, in principle, these embeddings should contain all information necessary for downstream machine learning tasks.\n",
        "\n",
        "Adopting this encoder-decoder view, we organize our discussion of the various node embedding methods along the following four methodological components:\n",
        "1. A **pairwise similarity function** s<sub>G</sub> : V × V → R+, defined over the graph G. This function measures the similarity between nodes in G.\n",
        "2. An **encoder function**, ENC, that generates the node embeddings. This function contains a number of trainable parameters that are optimized during the training phase.\n",
        "3. A **decoder function**, DEC, which reconstructs pairwise similarity values from the generated embeddings. This function usually contains no trainable parameters.\n",
        "4. A **loss function**, l, which determines how the quality of the pairwise reconstructions is evaluated in order to train the model, i.e., how DEC(**z**<sub>i</sub>, **z**<sub>j</sub> ) is compared to the true s<sub>G</sub> (v<sub>i</sub>, v<sub>j</sub>) values.\n",
        "\n",
        "\n",
        "### Encoder\n",
        "\n",
        "Formally, the encoder is a function,\n",
        "ENC : *V* → &#8477;<sup>d</sup>,\n",
        "that maps nodes to vector embeddings <b>z</b><sub>i</sub> ∈ &#8477;<sup>d</sup> (where z<sub>i</sub> corresponds to the embedding for node v<sub>i</sub> ∈ *V*). \n",
        "\n",
        "#### Convolutional Encoder\n",
        "Recently, deep learning algorithms have been applied to graph use cases, such as link prediction, with promising results. \n",
        "\n",
        "> In the last couple of years, a number of papers re-visited this problem of generalizing neural networks to work on arbitrarily structured graphs ([Bruna et al., ICLR 2014](http://arxiv.org/abs/1312.6203); [Henaff et al., 2015](http://arxiv.org/abs/1506.05163); [Duvenaud et al., NIPS 2015](http://papers.nips.cc/paper/5954-convolutional-networks-on-graphs-for-learning-molecular-fingerprints); [Li et al., ICLR 2016](https://arxiv.org/abs/1511.05493); [Defferrard et al., NIPS 2016](https://arxiv.org/abs/1606.09375); [Kipf & Welling, ICLR 2017](http://arxiv.org/abs/1609.02907), some of them now achieving very promising results in domains that have previously been dominated by, e.g., kernel-based methods, graph-based regularization techniques and others. [Kipf, ICLR 2017](https://tkipf.github.io/graph-convolutional-networks/)\n",
        "\n",
        "Currently, most graph neural network models have a somewhat universal architecture in common. I will refer to these models as Graph Convolutional Networks (GCNs); convolutional, because filter parameters are typically shared over all locations in the graph (or a subset thereof as in Duvenaud et al., NIPS 2015):\n",
        "> The lower layers of this network is convolutional in the sense that the same local filter is applied to each atom (node) and its neighborhood. After several such layers, a global pooling step combines features from all the atoms (nodes) in the molecule (neighborhood).  [Duvenaud et al., NIPS 2015](http://papers.nips.cc/paper/5954-convolutional-networks-on-graphs-for-learning-molecular-fingerprints)\n",
        "A number of recent node embedding approaches use encoders that rely on a node’s local neighborhood, but not necessarily the entire graph. \n",
        "\n",
        "The intuition behind these approaches is that they generate ***embeddings for a node by aggregating information from its local neighborhood***. \n",
        "\n",
        "<img src=\"https://blog.sourced.tech/content/images/2019/04/gg-nn.png\" width=\"80%\"/>\n",
        "\n",
        "Figure 6\n",
        "\n",
        "Overview of encoding in the neighborhood aggregation methods. To generate an embedding for node A, the model aggregates messages from A’s local graph neighbors (i.e., B, C, and D), and in turn, the messages coming from these neighbors are based on information aggregated from their respective neighborhoods, and so on. A “depth-2” version of this idea is shown (i.e., information is aggregated from a two-hop neighborhood around node A), but in principle these methods can be of an arbitrary depth. At the final “depth” or “layer” the initial messages are based on the input node attributes.\n",
        "\n",
        "These methods are often called *convolutional* because they represent a node as a function of its surrounding neighborhood, in a manner similar to the receptive field of a center-surround convolutional kernel in computer vision.\n",
        "\n",
        "### Pairwise Decoder\n",
        "The goal is to train our embedding to represent liklihood of edges between nodes. In principle, many decoders are possible; however, the vast majority of works use a basic pairwise decoder,\n",
        "\n",
        "DEC : &#8477;<sup>d</sup> × &#8477;<sup>d</sup> → &#8477;<sup>+</sup>\n",
        "\n",
        "that maps pairs of node embeddings to a real-valued node similarity measure, which quantifies the similarity of the two nodes in the original graph. When we apply the pairwise decoder to a pair of embeddings (<b>z</b><sub>i</sub>, <b>z</b><sub>j</sub>) we get a reconstruction of the similarity between v<sub>i</sub> and v<sub>j</sub> in the original graph, and the goal is optimize the encoder and decoder mappings to minimize the error, or loss, in this reconstruction so that:\n",
        "\n",
        "DEC(ENC(v<sub>i</sub>), ENC(v<sub>j</sub> )) = DEC(<b>z</b><sub>i</sub>, <b>z</b><sub>j</sub> ) ≈ s<sub>G</sub>(v<sub>i</sub>, v<sub>j</sub>),\n",
        "\n",
        "where s<sub>G</sub> is a user-defined, graph-based similarity measure between nodes, defined over the graph G. In this example, we will use s<sub>G</sub>(v<sub>j</sub> ) = A<sub>i</sub>,<sub>j</sub> and define nodes to have a similarity of 1 if they are adjacent and 0 otherwise.\n",
        "\n",
        "\n",
        "### Further Reading\n",
        "\n",
        "Thomas Kipf has published [really excellent articles](https://tkipf.github.io/graph-convolutional-networks/) about this area of technology, and this tutorial is based off of his basic network structure [outlined here](https://tkipf.github.io/graph-convolutional-networks/). You're encouraged to read Thomas's articles to get the full background on this technique. This exercise focuses on the application of it, as opposed to the background and theory.\n",
        "\n",
        "This area of technology is still in its infancy; The capabilties of GCN have not been fully charted. Whilst working on this exercise, embrace a healthy relish for research and the unknown!\n",
        "\n",
        "In what follows, we give a complete Tensorflow implementation of a two-layer graph convolutional neural network (GCN) for link prediction. We closely follow the GCN formulation as presented in [Kipf et al., ICLR 2017](https://arxiv.org/pdf/1609.02907.pdf).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgXU9BRRuQ-m",
        "colab_type": "text"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "We'll work with the Cora dataset. The Cora dataset consists of 2708 scientific publications classified into one of seven classes. The citation network consists of 5429 links. Each publication in the dataset is described by a 0/1-valued word vector indicating the absence/presence of the corresponding word from the dictionary. The dictionary consists of 1433 unique words. The README file in the dataset provides more details. \n",
        "\n",
        "Download Link \n",
        "https://linqs-data.soe.ucsc.edu/public/lbc/cora.tgz\n",
        "\n",
        "Related Papers: [Qing Lu, and Lise Getoor. \"Link-based classification.\" ICML, 2003](https://linqspub.soe.ucsc.edu/basilic/web/Publications/2003/lu:icml03/).\n",
        "\n",
        "[Prithviraj Sen, et al. \"Collective classification in network data.\" AI Magazine, 2008](https://linqspub.soe.ucsc.edu/basilic/web/Publications/2008/sen:aimag08/).\n",
        " \n",
        "\n",
        "## Demo\n",
        "\n",
        "In this demo, we formulate this prediction task as a link prediction problem on unweighted and undirected networks and use a graph convolutional neural network to solve the task.\n",
        "\n",
        "Note that link prediction is a standard prediction task, and thus this example can be easily extended and adapted to many other applications including biomedical and social graph cases.\n",
        "\n",
        "\n",
        "### Demo structure\n",
        "\n",
        "In this exercise you will create a fully functioning graph convolutional network. \n",
        "\n",
        "The exercise is a series of empty functions that you will fill out according to the instructions. There are then a series of unit tests to verify that your code works according to plan.\n",
        "\n",
        "### Library setup\n",
        "\n",
        "We'll write our code in Tensorflow 2.0. We'll also use Numpy and Scipy for some of the initial data manipulation. Let's load up all the libraries we'll need:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8L8WbnV1sRkY",
        "colab_type": "code",
        "outputId": "6450a9ab-63e1-4814-cfa3-c07f84d131b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "# Import all the libraries we need\n",
        "!pip uninstall -q -y tensorflow\n",
        "# install tensorflow 2\n",
        "!pip install -q tensorflow==2.0.0\n",
        "\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import tensorflow as tf\n",
        "from scipy.special import expit\n",
        "import scipy.sparse as sp\n",
        "from scipy.special import expit\n",
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import average_precision_score\n",
        "\n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "import collections\n",
        "from collections import namedtuple\n",
        "import unittest\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "\n",
        "print(\"TensorFlow version: \", tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 86.3MB 95kB/s \n",
            "\u001b[K     |████████████████████████████████| 450kB 51.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.8MB 60.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 81kB 9.4MB/s \n",
            "\u001b[31mERROR: tensorboard 2.0.1 has requirement grpcio>=1.24.3, but you'll have grpcio 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement google-auth~=1.4.0, but you'll have google-auth 1.7.1 which is incompatible.\u001b[0m\n",
            "\u001b[?25hTensorFlow version:  2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXC4ESW3Pq-m",
        "colab_type": "text"
      },
      "source": [
        "## Data loading\n",
        "We're going to use prepared data and code stored in a Kipf's [Graph Auto-Encoder github repo](https://github.com/tkipf/gae). The following code will download the data, the TensorFlow codebase, and load the data into memory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMWfUsmNQS3c",
        "colab_type": "code",
        "outputId": "9e3a9ace-2e93-468f-9971-c587eb5db498",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "%rm -rf /content/gae/\n",
        "# Thanks to TKipf for the code in github and also for researching the use of GCNs for link prediction\n",
        "!git clone https://github.com/tkipf/gae\n",
        "\n",
        "# Add the GCN repo to the import path\n",
        "sys.path.append('/content/gae/')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'gae'...\n",
            "remote: Enumerating objects: 73, done.\u001b[K\n",
            "remote: Total 73 (delta 0), reused 0 (delta 0), pack-reused 73\u001b[K\n",
            "Unpacking objects: 100% (73/73), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SikA8iROQvz5",
        "colab_type": "code",
        "outputId": "87b32e17-0829-40ae-9639-9ea77c5ada6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "# Load the data\n",
        "%cd -q /content/gae/\n",
        "\n",
        "from gae.input_data import load_data\n",
        "from gae.preprocessing import preprocess_graph, construct_feed_dict, sparse_to_tuple, mask_test_edges\n",
        "\n",
        "%cd -q /content/gae/gae/\n",
        "adj, features = load_data(\"cora\")\n",
        "\n",
        "adj_train, train_edges, val_edges, val_edges_false, test_edges, test_edges_false = mask_test_edges(adj)\n",
        "print(\"Loaded\",adj.shape[0],\"nodes\")\n",
        "print(\"Loaded\",adj.sum(),\"edges\")\n",
        "print()\n",
        "print(\"-- Data format --\")\n",
        "print(\"Full graph adjacency shape:    \", adj.shape, \"\\t\",             type(adj), \"number of indices\", len(adj.indices))\n",
        "print(\"Training graph adjacency shape:\", adj_train.shape, \"\\t\",       type(adj_train), \"number of indices\", len(adj_train.indices))\n",
        "print(\"val_edges:                     \", val_edges.shape, \"\\t\",       type(val_edges))\n",
        "print(\"val_edges_false:               \", len(val_edges_false), \"\\t\\t\",type(val_edges_false))\n",
        "print(\"test_edges:                    \", test_edges.shape,\"\\t\",       type(test_edges))\n",
        "print(\"test_edges_false:              \", len(test_edges_false),\"\\t\\t\",type(test_edges_false))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded 2708 nodes\n",
            "Loaded 10556 edges\n",
            "\n",
            "-- Data format --\n",
            "Full graph adjacency shape:     (2708, 2708) \t <class 'scipy.sparse.csr.csr_matrix'> number of indices 10556\n",
            "Training graph adjacency shape: (2708, 2708) \t <class 'scipy.sparse.csr.csr_matrix'> number of indices 8976\n",
            "val_edges:                      (263, 2) \t <class 'numpy.ndarray'>\n",
            "val_edges_false:                263 \t\t <class 'list'>\n",
            "test_edges:                     (527, 2) \t <class 'numpy.ndarray'>\n",
            "test_edges_false:               527 \t\t <class 'list'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNafHL_6nWmk",
        "colab_type": "text"
      },
      "source": [
        "## Graph Convolutional Network (GCN) Model\n",
        "\n",
        "Let's take a look at the GCN model in more detail. Previously, we defined a GCN to be convolutional in the sense that the same local filter is applied to node and its neighborhood. The intuition behind these approaches is that they generate embeddings for a node by aggregating information from its local neighborhood. After several such layers, a step combines features from all the nodes in the neighborhood similar to a [global pooling step](https://en.wikipedia.org/wiki/Convolutional_neural_network#Pooling) with [Convolutional Neural Networks](https://en.wikipedia.org/wiki/Convolutional_neural_network) (CNN).\n",
        "\n",
        "***A*** is the adjacency matrix that describes the edges that below to each pair of nodes in the graph. For each node i and j in the graph, if they have an edge from i to j, then adj[i][j] == 1.0, else 0.0. Every neural network layer can then be written as a non-linear function\n",
        "\n",
        "***H<sup>(l+1)</sup> = f(H<sup>(l)</sup>, A)***\n",
        "\n",
        "with ***H<sup>(0)</sup>=X*** and ***H<sup>(L)</sup>=Z*** (or *z* for graph-level outputs), ***L*** being the number of layers. The specific models then differ only in how ***f(⋅,⋅)*** is chosen and parameterized. \n",
        "\n",
        "### Propagation Rule\n",
        "As an example, let's consider the following very simple form of a layer-wise propagation rule:\n",
        "\n",
        "***f(H<sup>(l)</sup>,A) = σ(AH<sup>(l)</sup>W<sup>(l)</sup>)***,\n",
        "\n",
        "where ***W<sup>(l)</sup>*** is a weight matrix for the l-th neural network layer. It is the convolution (filter) in this model.\n",
        "\n",
        "***σ(⋅)*** is a non-linear activation function like the [ReLU](https://en.wikipedia.org/wiki/Rectifier_(neural_networks). \n",
        "\n",
        "### Limitations: Missing Self Links\n",
        "But first, let us address two limitations of this simple model: multiplication with ***A*** means that, for every node, we sum up all the feature vectors of all neighboring nodes plus the node itself. However, most adjacency matrices will have zeros for the node 'itself', except in cases where self-loops exist. In order to include the node's features along with its neighbors' features, we need to add a self-loop entry for the node. We can enforce self-loops in the graph by adding the identity matrix ***I*** to ***A***.\n",
        "\n",
        "### Limitations: Adjacency Matrix Not Normalized\n",
        "The second major limitation is that ***A*** is typically not normalized and therefore the multiplication with ***A*** will completely change the scale of the feature vectors (we can understand that by looking at the eigenvalues of ***A***). Normalizing ***A*** such that all rows sum to one, i.e. ***D<sup>−1</sup>A***, where ***D*** is the diagonal node degree matrix, gets rid of this problem. Multiplying with ***D<sup>−1</sup>A*** now corresponds to taking the average of neighboring node features. In practice, dynamics get more interesting when we use a symmetric normalization, i.e. ***D<sup>−1/2</sup>AD<sup>−1/2</sup>*** (as this no longer amounts to mere averaging of neighboring nodes). \n",
        "\n",
        "### Renormalization Trick\n",
        "Combining these two tricks, we essentially arrive at the propagation rule introduced in [Kipf et al., ICLR 2017](https://arxiv.org/pdf/1609.02907.pdf):\n",
        "\n",
        "***f(H<sup>(l)</sup>,A) = σ(D̂<sup>−1/2</sup>Â D̂<sup>−1/2</sup> H<sup>(l)</sup> W<sup>(l)</sup>)***,\n",
        "\n",
        "with ***Â = A + I***, where ***I*** is the identity matrix and ***D̂*** is the diagonal node degree matrix of ***Â***.\n",
        "\n",
        "### Further Reading\n",
        "See the [Kipf, Graph Convolutional Networks, 2017](https://tkipf.github.io/graph-convolutional-networks/) article for details.\n",
        "\n",
        "More information will provided in the following sections."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWmLF_OKYHs1",
        "colab_type": "text"
      },
      "source": [
        "## Data preparation\n",
        "\n",
        "Below the renormalization of the adjacency matrix is implemented.\n",
        "\n",
        "Note that the adjacency matrix is [sparse](https://en.wikipedia.org/wiki/Sparse_matrix): instead of storing every value in a *num nodes × num nodes × sizeof(float)* memory matrix (hint: that's a lot of memory!), just the non-zero values are stored as a list. Its internal structure is a [list of tuples](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html), each with a numeric value and a coordinate of where in the matrix that value appears. Storing it sparsely greatly reduces the memory footprint of the matrix.\n",
        "\n",
        "Note: the *preprocess_graph* and *sparse_to_tuple* methods are imported utlilty methods. See [gae/preprocessing.py](https://github.com/tkipf/gae/blob/master/gae/preprocessing.py)  for details."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYXB2nRusPAR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The preprocess_graph method implements the renormalization 'trick'. See above for details.\n",
        "adj_norm = preprocess_graph(adj)\n",
        "\n",
        "# Since the adj_train matrix was not created with diagonal entires, add them now.\n",
        "adj_label = adj_train + sp.eye(adj_train.shape[0])\n",
        "\n",
        "# Use sparse_to_tuple to 'unpack' the COO object into edges, normalized adjacency values and normalized adjacency shape\n",
        "adj_label = sparse_to_tuple(adj_label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PhlbTLyZLZQ",
        "colab_type": "text"
      },
      "source": [
        "## Simple GCNs\n",
        "\n",
        "As mentioned in the above section, GCNs use node features from a node's connected neighbors to do link prediction. One of the interesting conclusions from Kipf and Welling's research is that using the graph structure without any node features also (surprisingly?) results in accurate link predictions. \n",
        "\n",
        "The reader is encouraged to read Part III of the [Kipf's Graph Convolution Networks](https://tkipf.github.io/graph-convolutional-networks/) article for details on how a featureless approach results in accurate predictions.\n",
        "\n",
        "### Featureless Model\n",
        "\n",
        "Since this is training module, we will use the simplier, featureless approach, meaning the nodes in the Cora dataset will not have any features. \n",
        "\n",
        "Note: in a feature approach, the Cora dataset's node features are comprised of  a bag of words which are contained in the document (node). These words can be used to assist in predicting citation links. For example, documents that have a similar 'bag' of medical terms are more likely to have links than those that do not.\n",
        "\n",
        "Instead of including node features, Kipf and Welling recommend using the identiy matrix ***I*** as the initial feature matrix ***X***.  We use the [scipy.sparse.identity](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.identity.html?highlight=identity) function, using the number of nodes as a parameter, to generated the identity matrix.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVJwNSPRZWz9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Record the number of nodes and edges from the full adjacency matrix of the PPI yeast.edges dataset. Used below.\n",
        "num_nodes = adj.shape[0]\n",
        "\n",
        "# Simple GCN: no node features (featureless). Substitute the identity matrix for the feature matrix: X = I\n",
        "# The sparse_to_tuple method 'unpacks' the sparse diagonal matrix into a tuple of node coordinates, values and shape\n",
        "#\n",
        "features = sparse_to_tuple(sp.identity(num_nodes))\n",
        "\n",
        "# The features[2] dereferences the shape object in the features tuple. features[2][1] dereferences the number of unique nodes that can be neighbors of\n",
        "# any node in the graph. Since we are using an identity matrix, the num_features is equal to the number of nodes in the graph.\n",
        "# num_features are used by the GCN model below to define the input dimension size.\n",
        "num_features = features[2][1]\n",
        "\n",
        "# features[1] dereferences the data object in the features tuple and then use shape[0] to obtain the number of non-zero entries.\n",
        "# Since we are using an identity matrix, the features_nonzero is equal to the number of nodes in the graph.\n",
        "# features_nonzero is used by the dropout_sparse method to apply the dropout regularizer to non-zero features.\n",
        "features_nonzero = features[1].shape[0]\n",
        "\n",
        "# Dropout for sparse tensors. Currently fails for very large sparse tensors (>1M elements)\n",
        "def dropout_sparse(x, keep_prob, num_nonzero_elems):\n",
        "    noise_shape = [num_nonzero_elems]\n",
        "    random_tensor = keep_prob\n",
        "    random_tensor += tf.compat.v1.random_uniform(noise_shape)\n",
        "    dropout_mask = tf.cast(tf.floor(random_tensor), dtype=tf.bool)\n",
        "    pre_out = tf.compat.v1.sparse_retain(x, dropout_mask)\n",
        "    return pre_out * (1./keep_prob)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6hW9cKH2ZY-",
        "colab_type": "text"
      },
      "source": [
        "## Tensorflow layer\n",
        "\n",
        "Now for the exciting part, let's build a GCN layer in Tensorflow that we can use to construct a graph convolutional network.\n",
        "\n",
        "The layer takes the *node_state* *([identity matrix](https://www.mathbootcamps.com/the-identity-matrix-and-its-properties/))*\\* as the incoming tensor, then transforms that into a new *node_state*. It performs the following operations (many akin to a standard Dense layer):\n",
        "\n",
        "\n",
        "1.   [Dropout](https://machinelearningmastery.com/dropout-for-regularizing-deep-neural-networks/)\n",
        "2.   [Graph convolution](https://tkipf.github.io/graph-convolutional-networks/) (i.e. multiplying the node state (identity matrix) by the weights matrix)\n",
        "3.   [Graph propagation](https://tkipf.github.io/graph-convolutional-networks/) (i.e. multiplying the adjacency matrix by the node state)\n",
        "4.   [Activation function](https://towardsdatascience.com/activation-functions-neural-networks-1cbd9f8d91d6)\n",
        "\n",
        "\\* In a simple GCN model with no node features, the *identity matrix* is used as the node feature matrix (*X = I*). \n",
        "\n",
        "\n",
        "### Graph convolution\n",
        "This is convolution in the sense that the same parameters are being applied to each node state. This is in the form of a shared matrix, which transforms each node state just as a [dense layer](https://towardsdatascience.com/building-neural-network-from-scratch-9c88535bf8e9) would transform the activations in a feed-forward network.\n",
        "\n",
        "### Implementation details\n",
        "The layer takes the adjacency matrix (the sparse matrix representing graph connectivity) as a parameter in its constructor. The adjacency matrix does not change during training or testing as our graph is static.\n",
        "\n",
        "I've provided the main scaffold for the layer, initialising the weights and constructing the object.\n",
        "\n",
        "#### Glorot (Xavier) Initialization\n",
        "\n",
        "When you are working with deep neural networks, initializing the network with the right weights can be the hard to deal with because Deep Neural Networks suffer from problems called the [Vanishing/Exploding Gradients Problem](https://en.wikipedia.org/wiki/Vanishing_gradient_problem) . Therefore, we need the signal to flow properly in both directions: in the forward direction when making predictions, and in the reverse direction when backpropagating gradients. We don’t want the signal to die out, nor do we want it to explode and saturate. Source: [Weight Initialization Schemes, Arat](https://mmuratarat.github.io/2019-02-25/xavier-glorot-he-weight-init)\n",
        "\n",
        "One common initialization scheme for deep NNs is called Glorot (also known as Xavier) Initialization. The idea is to initialize each weight with a small Gaussian value with mean = 0.0 and variance based on the fan-in and fan-out of the weight. This works best for DNNs with multiple layers and a RELU activation function. Another way of saying this is to keep variance similar along all the layers of deep NN.  See [Understanding the difficulty of training deep feedforward neural networks](http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf) for details.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qj06_kqS1fhx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def weight_variable_glorot(input_dim, output_dim, name=\"\"):\n",
        "    \"\"\"Create a weight variable with Glorot & Bengio (AISTATS 2010) initialization.\n",
        "    \"\"\"\n",
        "    init_range = np.sqrt(6.0 / (input_dim + output_dim))\n",
        "    initial = tf.compat.v1.random_uniform(\n",
        "        [input_dim, output_dim],\n",
        "        minval=-init_range,\n",
        "        maxval=init_range,\n",
        "        dtype=tf.float32)\n",
        "    return tf.Variable(initial, name=name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqmtgmA8sx9M",
        "colab_type": "text"
      },
      "source": [
        "#### Encoder\n",
        "\n",
        "An encoder is a network (e.g., FC, RNN, GCN, etc.) that takes the input, and output a feature map/vector/tensor. These feature vectors hold the information, the features, that represents the input. In other words, the encoder maps each entity v<sub>i</sub> ∈ V to a real-valued vector e<sub>i</sub> ∈ R<sup>d</sup>.\n",
        "\n",
        "\n",
        "#### Graph Auto-encoder Model \n",
        "The research done by Schlichkrull, Kipf, et el. has computed representations through an R-GCN encoder with e<sub>i</sub> = h<sub>i</sub><sup>(L)</sup>, similar to the graph auto-encoder model introduced in [Variational Graph Auto-encoders, Kipf and Welling (2016)](https://arxiv.org/pdf/1611.07308.pdf) for unlabeled undirected graphs. [Modeling Relational Data with Graph Convolutional Networks, Schlichkrull, Kipf, et al., 2017](https://arxiv.org/abs/1703.06103). \n",
        "\n",
        "Below is an illustration of the architecture:\n",
        "\n",
        "![Graph Auto-encoder](https://github.com/tkipf/gae/raw/master/figure.png)\n",
        "\n",
        "Figure 7\n",
        "\n",
        "Source: https://github.com/tkipf/gae\n",
        "\n",
        "Notice that there are two hideen layers in the model above. These two layers will correspond to the next two classes described below:\n",
        "\n",
        "- 1st Hidden Layer -> GraphConvolutionSparse class\n",
        "- 2nd Hidden Layer -> GraphConvolution class\n",
        "\n",
        "Details are given below.\n",
        "\n",
        "### GraphConvolutionSparse Class\n",
        "\n",
        "First of all, this class's node state (inputs) is a implemented as a [SparseTensor](https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/sparse/placeholder).\n",
        "\n",
        "The adjacency and feature matrices [sparse](https://en.wikipedia.org/wiki/Sparse_matrix) in that instead of storing every value in a *num nodes × num nodes × sizeof(float)* memory matrix (hint: that's a lot of memory!), just the non-zero values are stored as a list. Its internal structure is a [list of tuples](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html), each with a numeric value and a coordinate of where in the matrix that value appears. Storing it sparsely greatly reduces the memory footprint of the matrix. Using a sparse representation for A, memory requirement is O(|E|), i.e. linear in the number of edges. \n",
        "\n",
        "#### Practice Exercise 1\n",
        "\n",
        "In order to reinforce the key ideas of link prediction with GCNs, this exercise will involve adding three lines of code to complete the graph convolution.\n",
        "\n",
        "Note: you may find this method useful: \n",
        "\n",
        "* [tf.sparse.sparse_dense_matmul](https://www.tensorflow.org/api_docs/python/tf/sparse/sparse_dense_matmul)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9yNXXW3HJUe",
        "colab_type": "code",
        "outputId": "d593b622-2069-4ccc-b21e-18b425c373bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "class GraphConvolutionSparse():\n",
        "    \"\"\"Graph convolution layer for sparse inputs.\"\"\"\n",
        "    def __init__(self, input_dim, output_dim, adj, features_nonzero, dropout=0., act=tf.nn.relu, **kwargs):\n",
        "        self.name = self.__class__.__name__.lower()\n",
        "        self.vars = {}\n",
        "        with tf.compat.v1.variable_scope(self.name + '_vars'):\n",
        "            self.vars['weights'] = weight_variable_glorot(input_dim, output_dim, name=\"weights\")\n",
        "        self.dropout = dropout\n",
        "        self.adj = adj\n",
        "        self.act = act\n",
        "        self.issparse = True\n",
        "        self.features_nonzero = features_nonzero\n",
        "\n",
        "    def __call__(self, inputs):\n",
        "        x = inputs\n",
        "        x = dropout_sparse(x, 1-self.dropout, self.features_nonzero)\n",
        "        # --- WRITE CODE HERE ---\n",
        "        x =       # apply a matrix multiply sparse tensor function with x and weights variable\n",
        "        x =       # apply a matrix multiply sparse tensor function with the adjacency matrix and x\n",
        "        outputs = # pass x to the activation function\n",
        "        # -----------------------\n",
        "        return outputs\n",
        "\n",
        "    def set_weights(self, weights):\n",
        "        self.vars['weights'] = weights\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-aef4c6084eff>\"\u001b[0;36m, line \u001b[0;32m18\u001b[0m\n\u001b[0;31m    x =       # apply a matrix multiply sparse tensor function with x and weights variable\u001b[0m\n\u001b[0m                                                                                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxxIKNNV-6uG",
        "colab_type": "text"
      },
      "source": [
        "### GraphConvolution Class\n",
        "\n",
        "Unlike the GraphConvolutionSparse class, this class has a node state (inputs) implemented as a standard [Tensor](https://www.tensorflow.org/api_docs/python/tf/Tensor), not a sparse one. The GraphConvolution class (hidden layer 2) is not sparse because the complete node state was output from the GraphConvolutionSparse class (hidden layer 1) as a standard tensor. \n",
        "\n",
        "Recall from a previous section the layer-wise propagation rule:\n",
        "\n",
        "***f(H<sup>(l)</sup>,A) = σ(AH<sup>(l)</sup>W<sup>(l)</sup>)***,\n",
        "\n",
        "***H<sup>(0)</sup>=X*** and ***H<sup>(L)</sup>=Z*** (or *z* for graph-level outputs), ***L*** being the number of layers. \n",
        "\n",
        "According to [Kipf and Welling, page 4](http://arxiv.org/abs/1609.02907), this propagation rule can be efficiently implemented as a product of a sparse matrix with a dense matrix. \n",
        "\n",
        "#### Practice Exercise 2\n",
        "\n",
        "In order to reinforce the key ideas of link prediction with GCNs, this exercise will involve adding three lines of code to complete the graph convolution. You may find the following functions useful:\n",
        "\n",
        "* [tf.matmul](https://www.tensorflow.org/api_docs/python/tf/linalg/matmul)\n",
        "* [tf.sparse.sparse_dense_matmul](https://www.tensorflow.org/api_docs/python/tf/sparse/sparse_dense_matmul)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_8PFxAy-4Da",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GraphConvolution():\n",
        "    \"\"\"Basic graph convolution layer for undirected graph without edge labels.\"\"\"\n",
        "    def __init__(self, input_dim, output_dim, adj, dropout=0., act=tf.nn.relu, **kwargs):\n",
        "        self.name = self.__class__.__name__.lower()\n",
        "        self.vars = {}\n",
        "        with tf.compat.v1.variable_scope(self.name + '_vars'):\n",
        "            self.vars['weights'] = weight_variable_glorot(input_dim, output_dim, name=\"weights\")\n",
        "        self.dropout = dropout\n",
        "        self.adj = adj\n",
        "        self.act = act\n",
        "        self.issparse = False\n",
        "\n",
        "    def __call__(self, inputs):\n",
        "        x = inputs\n",
        "        x = tf.compat.v1.nn.dropout(x, 1-self.dropout)\n",
        "        # --- WRITE CODE HERE ---\n",
        "        x =       # apply a matrix multiple function to x and the weights variable. Hint: are both matrices sparse or dense?\n",
        "        x =       # apply a matrix multiple function to x and the adjacency matrix. Hint: are both matrices sparse or dense? \n",
        "        outputs = # apply the activation function to x\n",
        "        # -----------------------\n",
        "        return outputs\n",
        "\n",
        "    def set_weights(self, weights):\n",
        "        self.vars['weights'] = weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-IfacuHhZwFK",
        "colab_type": "text"
      },
      "source": [
        "### Decoder\n",
        "\n",
        "The decoder is again a network (usually the same network structure as encoder but in opposite orientation) that takes the feature vector (embeddings) from the encoder, and gives the best closest match to the actual input or intended output. In other words, the decoder reconstructs edges of the graph relying on the vertex representations. [What is an Encoder/Decoder?](https://www.quora.com/What-is-an-Encoder-Decoder-in-Deep-Learning)\n",
        "\n",
        "\n",
        "#### Dot Product Measure of Vector Similarity\n",
        "\n",
        "Since the node embeddings are implemented as vectors, the strength of the relationship between two nodes is proportional to the *dot product* of their embeddings.  See [Cosine Similarity](https://en.wikipedia.org/wiki/Cosine_similarity) for more details on determining the similarity between two vectors.\n",
        "\n",
        "The larger the dot product scalar value, the greater the strength of the association between the nodes.  This scalar is passed to the logistic sigmoid (expit) to return a probability value on how likely a link exists between the nodes.\n",
        "\n",
        "Finally, the dot product is a normalized similarity measure and is less computational expensive compared to other measures.\n",
        "\n",
        "Note that our choice of node similarity function is arbitrary and other options could have been used.\n",
        "\n",
        "#### Practice Exercise 3\n",
        "\n",
        "In order to reinforce the key ideas of link prediction with GCNs, this exercise will involve adding four lines of code to complete the graph convolution decoding. These methods may be useful:\n",
        "\n",
        "* [tf.transpose](https://www.tensorflow.org/api_docs/python/tf/transpose)\n",
        "* [tf.matmul](https://www.tensorflow.org/api_docs/python/tf/linalg/matmul)\n",
        "* [tf.sparse.sparse_dense_matmul](https://www.tensorflow.org/api_docs/python/tf/sparse/sparse_dense_matmul)\n",
        "* [tf.reshape](https://www.tensorflow.org/api_docs/python/tf/reshape)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YXvqKNSZ2fd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# explain this in its own section and how it works. have text and diagram\n",
        "class InnerProductDecoder():\n",
        "    \"\"\"Decoder model layer for link prediction.\"\"\"\n",
        "    def __init__(self, input_dim, dropout=0., act=tf.nn.sigmoid, **kwargs):\n",
        "        self.dropout = dropout\n",
        "        self.act = act\n",
        "\n",
        "    def __call__(self, inputs):\n",
        "        inputs = tf.compat.v1.nn.dropout(inputs, 1-self.dropout)\n",
        "        # --- WRITE CODE HERE ---\n",
        "        x =       # transpose the inputs variable\n",
        "        x =       # apply a matrix multiple function to inputs and x\n",
        "        x =       # flatten x into a 1-D tensor \n",
        "        outputs = # apply the activation function to x\n",
        "        # -----------------------\n",
        "        return outputs\n",
        "\n",
        "    @staticmethod\n",
        "    def predict_using_embeddings(embeddings, edges):\n",
        "        # Taking the dot product of the (embeddings, embeddings.transpose) calculates the vector similarities between each \n",
        "        # pair of nodes.\n",
        "        # adj_rec: adjacency matrix reconstructed from the node embeddings.\n",
        "        adj_rec = np.dot(embeddings, embeddings.T)\n",
        "\n",
        "        # The sigmoid function will take the strength of the node pair (edge) relationship as a scalar value from the reconstructed \n",
        "        # adjacency matrix, and return the probability that the edge exists.\n",
        "        predictions = []\n",
        "        for e in edges:\n",
        "            # Note: the expit function is another name for the logistic sigmoid function\n",
        "            predictions.append(expit(adj_rec[e[0], e[1]]))\n",
        "        return predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5u3HidpqmFoc",
        "colab_type": "text"
      },
      "source": [
        "### Test the GCN Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17cTNB3VmKi7",
        "colab_type": "code",
        "outputId": "7813f2a5-71d6-40e5-dfbd-d304c0e82b4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "class TestLayer(unittest.TestCase):\n",
        "  def test_propagate_node_state(self):\n",
        "      # Create a dummy adjacency matrix\n",
        "      sparse_adj = tf.SparseTensor([(0, 1), (1, 0)], np.array([1.0, 1.0], np.float32), (3, 3))\n",
        "      gcs = GraphConvolutionSparse(3, 3, sparse_adj, 3)\n",
        "      weights = tf.constant([\n",
        "          [1.0, 0.0],\n",
        "          [0.0, 1.0],\n",
        "          [0.0, 0.0]\n",
        "      ])\n",
        "      gcs.set_weights(weights)\n",
        "      # Create an identity matrix below as the feature matrix X (node_state)\n",
        "      node_state = tf.SparseTensor([(0, 0), (1, 1), (2, 2)], np.array([1.0, 1.0, 1.0], np.float32), (3, 3))\n",
        "      result = gcs(node_state)\n",
        "      expected_result = [\n",
        "          [0.0, 1.0],\n",
        "          [1.0, 0.0],\n",
        "          [0.0, 0.0]\n",
        "      ]\n",
        "      np.testing.assert_allclose(result, expected_result, rtol=1e-03)\n",
        "      print(\"test_propagate_node_state Success!\")\n",
        "\n",
        "  def test_apply_convolution(self):\n",
        "      sparse_adj = tf.SparseTensor([(0, 1), (1, 0)], np.array([1.0, 1.0], np.float32), (3, 3))\n",
        "      gcs = GraphConvolution(3, 3, sparse_adj)\n",
        "      weights = tf.constant([\n",
        "          [0.0, 1.0],\n",
        "          [1.0, 0.0],\n",
        "      ])\n",
        "      gcs.set_weights(weights)\n",
        "      # Create an identity matrix below as the feature matrix (node_state) X\n",
        "      node_state = tf.constant([\n",
        "          [1.0, 0.0],\n",
        "          [1.0, 0.0],\n",
        "          [0.0, 0.0]\n",
        "      ], tf.float32)\n",
        "      node_state = tf.convert_to_tensor(node_state, dtype=tf.float32)\n",
        "      result = gcs(node_state)\n",
        "      expected_result = [\n",
        "          [0.0, 1.0],\n",
        "          [0.0, 1.0],\n",
        "          [0.0, 0.0]\n",
        "      ]\n",
        "      np.testing.assert_allclose(result, expected_result, rtol=1e-03)\n",
        "      print(\"test_apply_convolution Success!\")\n",
        "\n",
        "  def test_decoder(self):\n",
        "      embeddings = [\n",
        "          [0.0, 1.0],\n",
        "          [0.0, 1.0],\n",
        "          [0.0, 0.0]\n",
        "      ]\n",
        "      embeddings = tf.convert_to_tensor(embeddings, dtype=tf.float32)\n",
        "      decoder = InnerProductDecoder(3, act=lambda x: x)\n",
        "      result = decoder(embeddings)\n",
        "      expected_result = np.array([1., 1., 0., 1., 1., 0., 0., 0., 0.])\n",
        "      np.testing.assert_allclose(result, expected_result, rtol=1e-03)\n",
        "      print(\"test_decoder_Success!\")\n",
        "\n",
        "t = TestLayer()\n",
        "t.test_propagate_node_state()\n",
        "t.test_apply_convolution()\n",
        "t.test_decoder()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_propagate_node_state Success!\n",
            "test_apply_convolution Success!\n",
            "test_decoder_Success!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gu2upjnsIBV7",
        "colab_type": "text"
      },
      "source": [
        "## Tensorflow model\n",
        "\n",
        "Now we have a working GCN layer, let's put it to work in a Tensorflow model. We will stack multiple layers linearly, passing the output of one as the input to the next.\n",
        "\n",
        "We're going to build the following network architecture - two layers, with the following parameters:\n",
        "\n",
        "1.   Output units = 32, activation = relu\n",
        "2.   Output units = 16, activation = identity function\n",
        "\n",
        "We'll give each layer our prepared adjacency matrix from earlier.\n",
        "\n",
        "I've provided hyper-parameters for the number of units in each \n",
        "GCN layer and [dropout](https://machinelearningmastery.com/dropout-for-regularizing-deep-neural-networks/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5i6qNPiPKC3r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "HIDDEN1=32\n",
        "HIDDEN2=16\n",
        "DROPOUT=0.1\n",
        "\n",
        "class GCNModelAE():\n",
        "    def __init__(self, placeholders, num_features, features_nonzero, **kwargs):\n",
        "        self.name = self.__class__.__name__.lower()\n",
        "        self.inputs = placeholders['features']\n",
        "        self.input_dim = num_features\n",
        "        self.features_nonzero = features_nonzero\n",
        "        self.adj = placeholders['adj']\n",
        "        self.dropout = placeholders['dropout']\n",
        "        self.build()\n",
        "\n",
        "    def _build(self):\n",
        "        self.hidden1 = GraphConvolutionSparse(input_dim=self.input_dim,\n",
        "                                              output_dim=HIDDEN1,\n",
        "                                              adj=self.adj,\n",
        "                                              features_nonzero=self.features_nonzero,\n",
        "                                              act=tf.nn.relu,\n",
        "                                              dropout=self.dropout)(self.inputs)\n",
        "\n",
        "        self.embeddings = GraphConvolution(input_dim=HIDDEN1,\n",
        "                                           output_dim=HIDDEN2,\n",
        "                                           adj=self.adj,\n",
        "                                           act=lambda x: x,\n",
        "                                           dropout=self.dropout)(self.hidden1)\n",
        "\n",
        "        self.z_mean = self.embeddings\n",
        "\n",
        "        self.reconstructions = InnerProductDecoder(input_dim=HIDDEN2,\n",
        "                                      act=lambda x: x)(self.embeddings)\n",
        "\n",
        "    def build(self):\n",
        "        \"\"\" Wrapper for _build() \"\"\"\n",
        "        with tf.compat.v1.variable_scope(self.name):\n",
        "            self._build()\n",
        "        variables = tf.compat.v1.get_collection(tf.compat.v1.GraphKeys.GLOBAL_VARIABLES, scope=self.name)\n",
        "        self.vars = {var.name: var for var in variables}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uBx31AhOf3V",
        "colab_type": "text"
      },
      "source": [
        "### Optimizer\n",
        "I've provided a custom Optimizer class. At its core, this custom optimizer uses a [weighted cross entropy with logits](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/nn/weighted_cross_entropy_with_logits) loss function.  A value pos_weight > 1 decreases the false negative count, hence increasing the recall. This can be seen from the fact that pos_weight is introduced as a multiplicative coefficient for the positive labels term in the loss expression:\n",
        "\n",
        "An explanation for this choice of loss function is mentioned in [Modeling Relational Data with Graph Convolutional Networks](https://arxiv.org/pdf/1703.06103.pdf), page 4:\n",
        "\n",
        ">As in previous work on factorization (Yang et al. 2014;\n",
        "Trouillon et al. 2016), we train the model with negative\n",
        "sampling. For each observed example we sample ω negative ones. We sample by randomly corrupting either the subject or the object of each positive example. We optimize for cross-entropy loss to push the model to score observable\n",
        "triples higher than the negative ones.\n",
        "\n",
        "The `norm` variable accounts for the sparsity of positive links in the graph. Since we are increasing the weight of the positive links with the `pos_weight` variable, the `norm` variable normalizes this cost according to the sparsity.  The fewer the positive links, the smaller the normalization factor value. The higher the positive links, the larger the value.\n",
        "\n",
        " [Adam](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/) is used as the Tensorflow optimizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5FVYh6TUCQk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LEARNING_RATE=0.1\n",
        "\n",
        "class OptimizerAE(object):\n",
        "    def __init__(self, preds, labels, pos_weight, norm):\n",
        "        preds_sub = preds\n",
        "        labels_sub = labels\n",
        "\n",
        "        self.cost = norm * tf.reduce_mean(tf.compat.v1.nn.weighted_cross_entropy_with_logits(logits=preds_sub, labels=labels_sub, pos_weight=pos_weight))\n",
        "        self.optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=LEARNING_RATE)  # Adam Optimizer\n",
        "\n",
        "        self.opt_op = self.optimizer.minimize(self.cost)\n",
        "        self.grads_vars = self.optimizer.compute_gradients(self.cost)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pekfwIzIeM3c",
        "colab_type": "text"
      },
      "source": [
        "## Doing Predictions \n",
        "\n",
        "Recall that we are using the learned node embeddings to do predictions, use code below to implement this approach.\n",
        "\n",
        "See the *InnerProductDecoder.predict_using_embeddings* method defined above for how the predictions are calculated. \n",
        "\n",
        "The predictions are done separately on postive and negative edges, combined into one dataset, and then passed to [sklearn.metrics.roc_auc_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score) and \n",
        "[sklearn.metrics.average_precision_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.average_precision_score.html) methods to calculate ROC and average precision respectively.\n",
        "\n",
        "### ROC Curve\n",
        "\n",
        "A receiver operating characteristic curve, or [ROC](https://en.wikipedia.org/wiki/Receiver_operating_characteristic) curve, is a graphical plot that illustrates the diagnostic ability of a binary classifier system as its discrimination threshold is varied. To draw an ROC curve, only the true positive rate (TPR) and false positive rate (FPR) are needed (as functions of some classifier parameter). The TPR defines how many correct positive results occur among all positive samples available during the test. FPR, on the other hand, defines how many incorrect positive results occur among all negative samples available during the test.\n",
        "\n",
        "#### ROC Space\n",
        "\n",
        "An ROC space is defined by FPR and TPR as x and y axes, respectively, which depicts relative trade-offs between true positive (benefits) and false positive (costs). Since TPR is equivalent to sensitivity and FPR is equal to 1 − specificity, the ROC graph is sometimes called the sensitivity vs (1 − specificity) plot. Each prediction result or instance of a confusion matrix represents one point in the ROC space.\n",
        "\n",
        "#### Understanding ROC Values\n",
        "The best possible prediction method would yield a point in the upper left corner or coordinate (0,1) of the ROC space, representing 100% sensitivity (no false negatives) and 100% specificity (no false positives). The (0,1) point is also called a perfect classification. A random guess would give a point along a diagonal line (the so-called line of no-discrimination) from the left bottom to the top right corners (regardless of the positive and negative base rates). An intuitive example of random guessing is a decision by flipping coins. As the size of the sample increases, a random classifier's ROC point tends towards the diagonal line. In the case of a balanced coin, it will tend to the point (0.5, 0.5).  Here is an example:\n",
        "\n",
        "![Sample ROC Curve](https://upload.wikimedia.org/wikipedia/commons/thumb/3/36/ROC_space-2.png/500px-ROC_space-2.png)\n",
        "\n",
        "Figure 8\n",
        "\n",
        "The diagonal divides the ROC space. Points above the diagonal represent good classification results (better than random); points below the line represent bad results (worse than random).\n",
        "\n",
        "When using normalized units, the area under the curve (often referred to as simply the AUC) is equal to the probability that a classifier will rank a randomly chosen positive instance higher than a randomly chosen negative one (assuming 'positive' ranks higher than 'negative').\n",
        "\n",
        "### Average Precision\n",
        "\n",
        "[AP](https://en.wikipedia.org/wiki/Evaluation_measures_(information_retrieval)#Average_precision) summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold, with the increase in recall from the previous threshold used as the weight:\n",
        "\n",
        "<img src=\"https://i.ibb.co/qMv4HMK/Screen-Shot-2019-10-29-at-11-17-45-AM.png\" width=\"20%\"/>\n",
        "\n",
        "where *k* is the rank in the sequence of retrieved documents, *n* is the number of retrieved documents, *P(k)* is the precision at cut-off *k* in the list, and  &#916;*r(k)* is the change in recall from items *k-1* to *k*. The closer the AP is to 1.0, the fewer false positives and false negatives predicted from the model.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLoulR5Pewq_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_roc_score(edges_pos, edges_neg):\n",
        "    # Since we are using the embeddings in a test scenario, recalculate them with no dropout. \n",
        "    feed_dict.update({placeholders['dropout']: 0})\n",
        "    emb = sess.run(model.embeddings, feed_dict=feed_dict)\n",
        "       \n",
        "    # Since we are using the embeddings in a test scenario, recalculate them with no dropout.\n",
        "    feed_dict.update({placeholders['dropout']: 0})\n",
        "    emb = sess.run(model.embeddings, feed_dict=feed_dict)\n",
        "    \n",
        "    # Predict on test set of positive edges\n",
        "    preds = InnerProductDecoder.predict_using_embeddings(emb, edges_pos)\n",
        "    \n",
        "    # Predict on test set of negative edges\n",
        "    preds_neg = InnerProductDecoder.predict_using_embeddings(emb, edges_neg)\n",
        "\n",
        "    # Stack positive/negative predictions and labels \n",
        "    preds_all = np.hstack([preds, preds_neg])\n",
        "    labels_all = np.hstack([np.ones(len(preds)), np.zeros(len(preds_neg))])\n",
        "    \n",
        "    # Calculate scores\n",
        "    roc_score = roc_auc_score(labels_all, preds_all)\n",
        "    ap_score = average_precision_score(labels_all, preds_all)\n",
        "\n",
        "    return roc_score, ap_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZP5J0DQOOA_v",
        "colab_type": "text"
      },
      "source": [
        "## Train the model\n",
        "\n",
        "Finally, let's train the model.  Running this assumes the user has some familiarity with running [TensorFlow](https://www.tensorflow.org/) models. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHdLMHbuOTMl",
        "colab_type": "code",
        "outputId": "197061b4-66c0-46e5-d13f-aa456d31f6a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "NUM_EPOCHS=200\n",
        "DROPOUT=0.1\n",
        "\n",
        "def construct_feed_dict(adj_normalized, adj, features, placeholders):\n",
        "    # construct feed dictionary\n",
        "    feed_dict = dict()\n",
        "    feed_dict.update({placeholders['features']: features})\n",
        "    feed_dict.update({placeholders['adj']: adj_normalized})\n",
        "    feed_dict.update({placeholders['adj_orig']: adj})\n",
        "    return feed_dict\n",
        "\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "\n",
        "# Define placeholders\n",
        "placeholders = {\n",
        "    'features': tf.compat.v1.sparse_placeholder(tf.float32),\n",
        "    'adj': tf.compat.v1.sparse_placeholder(tf.float32),\n",
        "    'adj_orig': tf.compat.v1.sparse_placeholder(tf.float32),\n",
        "    'dropout': tf.compat.v1.placeholder_with_default(0., shape=())\n",
        "}\n",
        "\n",
        "# Create model\n",
        "model = GCNModelAE(placeholders, num_features, features_nonzero)\n",
        "\n",
        "pos_weight = float(adj.shape[0] * adj.shape[0] - adj.sum()) / adj.sum()\n",
        "norm = adj.shape[0] * adj.shape[0] / float((adj.shape[0] * adj.shape[0] - adj.sum()) * 2)\n",
        "\n",
        "# Optimizer\n",
        "with tf.name_scope('optimizer'):\n",
        "    opt = OptimizerAE(preds=model.reconstructions,\n",
        "                      labels=tf.reshape(tf.compat.v1.sparse_tensor_to_dense(placeholders['adj_orig'],\n",
        "                                                                  validate_indices=False), [-1]),\n",
        "                      pos_weight=pos_weight,\n",
        "                      norm=norm)\n",
        " \n",
        "print(\"Finished creating optimizer\")\n",
        "\n",
        "# Initialize session\n",
        "print(\"Start session\")\n",
        "sess = tf.compat.v1.Session()\n",
        "sess.run(tf.compat.v1.global_variables_initializer())\n",
        "\n",
        "# Construct feed dictionary\n",
        "feed_dict = construct_feed_dict(adj_norm, adj_label, features, placeholders)\n",
        "\n",
        "cost_val = []\n",
        "ap_val = []\n",
        "auc_score_val = []\n",
        "# Train model\n",
        "print(\"Epochs: \")\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    t = time.time()\n",
        "    # Construct feed dictionary\n",
        "    feed_dict = construct_feed_dict(adj_norm, adj_label, features, placeholders)\n",
        "    feed_dict.update({placeholders['dropout']: DROPOUT})\n",
        "    # Run single weight update\n",
        "    outs = sess.run([opt.opt_op, opt.cost], feed_dict=feed_dict)\n",
        "\n",
        "    # Compute average loss\n",
        "    avg_cost = outs[1]\n",
        "    cost_val.append(avg_cost)\n",
        "\n",
        "    roc_curr, ap_curr = get_roc_score(val_edges, val_edges_false)\n",
        "    ap_val.append(ap_curr)\n",
        "    auc_score_val.append(roc_curr)\n",
        "\n",
        "    # print(\"Epoch:\", '%04d' % (epoch + 1), \n",
        "    #      \"train_loss=\", \"{:.5f}\".format(avg_cost),\n",
        "    #      \"val_roc=\", \"{:.5f}\".format(roc_curr[-1]),\n",
        "    #      \"val_ap=\", \"{:.5f}\".format(ap_curr),\n",
        "    #      \"time=\", \"{:.5f}\".format(time.time() - t))\n",
        "    if epoch % 40 == 0:\n",
        "      print(\"\")\n",
        "    print(epoch, end =\" \")\n",
        "\n",
        "print('\\nOptimization Finished!')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finished creating optimizer\n",
            "Start session\n",
            "Epochs: \n",
            "\n",
            "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 \n",
            "40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 \n",
            "80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 \n",
            "120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 \n",
            "160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 \n",
            "Optimization Finished!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqikApUyF_HE",
        "colab_type": "code",
        "outputId": "c970c109-5a36-44cf-cdc3-8f81e9599748",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 746
        }
      },
      "source": [
        "# Display graphs of how the model performed\n",
        "from scipy.ndimage.filters import gaussian_filter1d\n",
        "\n",
        "print(\"Final loss: \", cost_val[-1])\n",
        "\n",
        "plt.rcParams['figure.figsize'] = [15, 10]\n",
        "\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(cost_val)\n",
        "plt.title(\"Training loss\")\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.plot(ap_val)\n",
        "plt.title(\"Average Precision (AP)\")\n",
        "plt.ylabel('AP')\n",
        "plt.xlabel('Epoch')\n",
        "\n",
        "plt.subplot(2, 2, 3)\n",
        "plt.plot(auc_score_val)\n",
        "plt.title(\"Area Under Curve(AUC)\")\n",
        "plt.ylabel('AUC')\n",
        "plt.xlabel('Epoch')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Final loss:  0.41271728\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABDAAAALICAYAAACJhQBYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLYKAmthyz8YAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1080x720 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BgLxhuZsP7B",
        "colab_type": "text"
      },
      "source": [
        "## Test the model\n",
        "\n",
        "Rerun the model with hold-out test datasets: test_edges, test_edges_false."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hL3djXkUsSba",
        "colab_type": "code",
        "outputId": "3aba5072-86b2-44d2-d797-3f4fb7c7b2e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "roc_score, ap_score = get_roc_score(test_edges, test_edges_false)\n",
        "print('Test AUC score: {:.5f}'.format(roc_score))\n",
        "print('Test AP score: {:.5f}'.format(ap_score))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test AUC score: 0.98276\n",
            "Test AP score: 0.98177\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6zkz7f6sk42",
        "colab_type": "text"
      },
      "source": [
        "## Comparing Results to Published Research\n",
        "\n",
        "Kipf and Welling in their paper [Variational Graph Auto-Encoders, 2016](https://arxiv.org/pdf/1611.07308.pdf) reported link prediction results (Table 1) for the Cora dataset:\n",
        "\n",
        "**AUC: 91.0 ± 0.02**\n",
        "\n",
        "**AP: 92.0 ± 0.0**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVdJOw33stqX",
        "colab_type": "text"
      },
      "source": [
        "## Exercise questions\n",
        "\n",
        "\n",
        "[Add your answers and discoveries to the answer document](https://docs.google.com/document/d/1bNm0yVGTtW12y52-vyMzOGouh9M6dhtIm6xmDpA5xSQ/edit?usp=sharing)\n",
        "\n",
        "\n",
        "- What AUC and average precision did you get?\n",
        "\n",
        "- What did you observe regarding the Cost, AP and AUC curves?\n",
        "\n",
        "- Did you perform better or worse than the Kipf and Welling?\n",
        "\n",
        "- How would you scale this network to a larger graph? What challenges might you encounter?\n",
        "\n",
        "## Feedback\n",
        "\n",
        "You can send feedback to [Paul Sterk](mailto:paul.j.sterk@gmail.com), the [Octavian Discord Chat Channel](https://discordapp.com/channels/391272409681887255/391272410252574732) or the [Octavian Mailing List](mailto:hello@octavian.ai).\n",
        "\n"
      ]
    }
  ]
}